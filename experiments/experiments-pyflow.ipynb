{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "import json\n",
    "import tempfile\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as trans\n",
    "import torchvision.models\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "import vmdata\n",
    "import more_trans\n",
    "from pyflow import coarse2fine_flow as opticalflow\n",
    "\n",
    "from ezfirstae.loaddata import SlidingWindowBatchSampler\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flow_params`:\n",
    "\n",
    "- alpha\n",
    "- ratio ($\\in [0.4, 0.98]$)\n",
    "- minWidth\n",
    "- nOuterFPIterations\n",
    "- nInnerFPIterations\n",
    "- nSORIterations\n",
    "- colType (0 for RGB, 1 for GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FlowParams = collections.namedtuple('FlowParams', (\n",
    "    'alpha', 'ratio', 'minWidth', 'nOuterFPIterations', 'nInnerFPIterations',\n",
    "    'nSORIterations', 'colType'))\n",
    "FlowParams_colType = {'rgb': 0, 'gray': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_params = FlowParams(\n",
    "    alpha=0.012,\n",
    "    ratio=0.75,\n",
    "    minWidth=20,\n",
    "    nOuterFPIterations=7,\n",
    "    nInnerFPIterations=1,\n",
    "    nSORIterations=30,\n",
    "    colType=FlowParams_colType['gray'],\n",
    ")\n",
    "\n",
    "assert 0.4 <= flow_params.ratio <= 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_flow(u, v):\n",
    "    assert u.shape == v.shape\n",
    "    hsv = np.zeros(u.shape[:2]+(3,), dtype=np.uint8)\n",
    "    hsv[:, :, 0] = 255\n",
    "    hsv[:, :, 1] = 255\n",
    "    mag, ang = cv2.cartToPolar(u, v)\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB).astype(np.float64) / 255.0\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opticalflow_caller(image_pair):\n",
    "    im1, im2 = image_pair\n",
    "    u, v, _ = opticalflow(im1, im2, *flow_params)\n",
    "    uv = np.stack((u, v), axis=2)\n",
    "    return uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flows(settings, num_workers=1):\n",
    "    root = settings['data']['root']\n",
    "    transform = [trans.ToTensor()]\n",
    "    if settings['data']['normalize']:\n",
    "        transform.append(trans.Normalize(*vmdata.get_normalization_stats(root, bw=True)))\n",
    "    transform = trans.Compose(transform)\n",
    "    indices = settings['data']['indices']\n",
    "    flow_params = FlowParams(**settings['flow'])\n",
    "    \n",
    "    all_uvs = []\n",
    "    with vmdata.VideoDataset(root, transform=transform) as vdset:\n",
    "        sam = SlidingWindowBatchSampler(indices, 2,\n",
    "                                        batch_size=num_workers, drop_last=True)\n",
    "        dataloader = DataLoader(vdset, batch_sampler=sam)\n",
    "        with multiprocessing.Pool(num_workers) as pool:\n",
    "            for j, image_pairs in tqdm(enumerate(map(more_trans.chw2hwc, more_trans.numpy_loader(dataloader))),\n",
    "                                       total=int(np.ceil((len(indices)-1)/num_workers)), ascii=True):\n",
    "                image_pairs = np.split(image_pairs.astype(np.float64).copy(order='C'),\n",
    "                                       num_workers, axis=0)\n",
    "                uvs = pool.map(opticalflow_caller, image_pairs)\n",
    "                all_uvs.extend(uvs)\n",
    "                if j and j % 2 == 0:\n",
    "                    gc.collect()\n",
    "    all_uvs = np.stack(all_uvs)  # shape: NHW2\n",
    "    return all_uvs\n",
    "\n",
    "def load_json(filename):\n",
    "    with open(filename) as infile:\n",
    "        return json.load(infile)\n",
    "\n",
    "def compute_flows_caller(settings, num_workers=1):\n",
    "    basedir = 'data.experiments-flow/flows'\n",
    "    all_setting_files = [os.path.join(basedir, x)\n",
    "                         for x in os.listdir(basedir)\n",
    "                         if x.endswith('.json')]\n",
    "    all_settings = list(map(load_json, all_setting_files))\n",
    "    try:\n",
    "        found = all_settings.index(settings)\n",
    "    except ValueError:\n",
    "        all_uvs = compute_flows(settings, num_workers=num_workers)\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, dir=basedir,\n",
    "                                         prefix='flowd_', suffix='.json') as outfile:\n",
    "            filename = os.path.splitext(outfile.name)[0]\n",
    "            json.dump(settings, outfile)\n",
    "        np.save(filename + '.npy', all_uvs)\n",
    "    else:\n",
    "        data = os.path.splitext(all_setting_files[found])[0] + '.npy'\n",
    "        all_uvs = np.load(data)\n",
    "    return all_uvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = vmdata.prepare_dataset_root(9, (8, 0, 0))\n",
    "normalize = trans.Normalize(*vmdata.get_normalization_stats(root, bw=True))\n",
    "transform = trans.Compose([\n",
    "    trans.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "indices = np.arange(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_settings = flow_params._asdict()\n",
    "data_settings = {'root': root, 'normalize': trans.Normalize in map(type, transform.transforms),\n",
    "                 'indices': list(map(int, indices))}\n",
    "settings = {'flow': flow_settings, 'data': data_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_flows_caller(settings, num_workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
